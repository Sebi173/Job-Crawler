{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import urlparse, urljoin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('JobsDataframe.csv')\n",
    "\n",
    "known_job_ids = df.ID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jobscout24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://www.jobscout24.ch/de/jobs/'\n",
    "\n",
    "known_job_ids = df[df.JobsSite == 'Jobscout24'].ID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Job URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_job_urls_on_page(url):\n",
    "    \n",
    "    job_urls = []\n",
    "    \n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    soup_articles = soup.find_all(\"li\", {\"class\": \"job-list-item\"})\n",
    "    page = url.split('=')[-1]\n",
    "    \n",
    "    for soup_article in soup_articles:\n",
    "\n",
    "        job_dic = {}\n",
    "        index_id = str(soup_article).index('data-job-id')\n",
    "        data_id = str(soup_article)[index_id + len('data-job-id='):].split('\"')[1]\n",
    "        article_url = f'{main_url}?jobId={data_id}'\n",
    "        job_dic['ArticleURL'] = article_url\n",
    "        job_dic['Page'] = page\n",
    "        job_dic['MainURL'] = url\n",
    "        job_dic['ID'] = data_id\n",
    "        job_urls.append(job_dic)\n",
    "    \n",
    "    \n",
    "    return job_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_job_urls(url, pages):\n",
    "    \n",
    "    \n",
    "    all_job_urls = []\n",
    "    job_dic = {}\n",
    "    for page in range(pages):\n",
    "        next_page_url = f'{url}?p={page+1}'\n",
    "        all_job_urls += find_job_urls_on_page(next_page_url)\n",
    "        \n",
    "    return all_job_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get URLs based on Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = [\n",
    "    'Data Analyst',\n",
    "    'Data Scientist',\n",
    "    'Python Developer',\n",
    "    'Python',\n",
    "    'Mathematik',\n",
    "    'Software Engineer',\n",
    "    'Software Developer'\n",
    "]\n",
    "\n",
    "df_links = pd.DataFrame()\n",
    "\n",
    "for search_term in search_terms:\n",
    "    \n",
    "    search_term_reworked = search_term.replace(' ', '%20').lower()\n",
    "    search_term_url = f'{main_url}/{search_term_reworked}/'\n",
    "    job_urls = find_all_job_urls(search_term_url, 5)\n",
    "    df_new_links = pd.DataFrame(job_urls)\n",
    "    df_new_links['SearchTerm'] = search_term\n",
    "    df_links = df_links.append(df_new_links, ignore_index = True)\n",
    "\n",
    "df_links['Date'] = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_ids = df_links.ID.value_counts().reset_index()\n",
    "df_count_ids.columns = ['ID', 'NumberOfOccurences']\n",
    "\n",
    "df_links_extended = df_links.merge(df_count_ids, on = 'ID', how = 'left')\n",
    "\n",
    "df_links_extended.Page = df_links_extended.Page.astype('int64')\n",
    "df_links_extended.ID = df_links_extended.ID.astype('int64')\n",
    "df_links_extended.NumberOfOccurences = df_links_extended.NumberOfOccurences.astype('int64')\n",
    "\n",
    "df_links_extended.Date = pd.to_datetime(df_links_extended.Date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Content from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_content(url):\n",
    "    \n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    job_description_soup = soup.find('div', {'class': 'slim_text'})\n",
    "    job_title_soup = soup.find('div', {'class': 'slim_title'})\n",
    "    company_title_soup = soup.find('h2', {'class': 'company-title'})\n",
    "    company_location_soup = soup.find('a', {'class': 'company-location'})\n",
    "    \n",
    "    try:\n",
    "        job_description = job_description_soup.get_text()\n",
    "    except:\n",
    "        job_description = 'Cannot access url'\n",
    "        \n",
    "    try:\n",
    "        job_title = job_title_soup.get_text()\n",
    "    except:\n",
    "        job_title = 'Cannot access url'\n",
    "        \n",
    "    try:\n",
    "        company_title = company_title_soup.get_text()\n",
    "    except:\n",
    "        company_title = 'Cannot access url'   \n",
    "        \n",
    "    try:\n",
    "        company_location = company_location_soup.get_text()\n",
    "    except:\n",
    "        company_location = 'Cannot access url'\n",
    "        \n",
    "    \n",
    "    return job_description, job_title, company_title, company_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_links_extended[~df_links_extended.ID.isin(known_job_ids)].copy()\n",
    "df_new = df_new.drop_duplicates(subset='ID')\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "\n",
    "df_new.columns = ['ArticleURL', 'Page', 'MainURL', 'ID', 'SearchTerm', 'FirstDate',\n",
    "       'NumberOfOccurences']\n",
    "\n",
    "df_new['LatestDate'] = df_new.FirstDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_job_data = pd.DataFrame(df_new.ArticleURL.map(lambda url: get_job_content(url)).tolist())\n",
    "\n",
    "df_new['JobDescription'] = df_new_job_data[0]\n",
    "df_new['JobTitle'] = df_new_job_data[1]\n",
    "df_new['CompanyName'] = df_new_job_data[2]\n",
    "df_new['CompanyLocation'] = df_new_job_data[3]\n",
    "df_new['JobsSite'] = 'Jobscout24'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_mining_job_title(dataframe):\n",
    "    dataframe['JobDescriptionLength'] = dataframe.JobTitle.map(lambda x: len(x))\n",
    "    dataframe['OneHotDataAnalyst'] = dataframe.JobTitle.str.lower().str.contains('data analyst').astype(int)\n",
    "    dataframe['OneHotDataScientist'] = dataframe.JobTitle.str.lower().str.contains('data scientist').astype(int)\n",
    "    dataframe['OneHotPython'] = dataframe.JobTitle.str.lower().str.contains('python').astype(int)\n",
    "    dataframe['OneHotDeveloper'] = dataframe.JobTitle.str.lower().str.contains('developer').astype(int)\n",
    "    dataframe['OneHotEngineer'] = dataframe.JobTitle.str.lower().str.contains('engineer').astype(int)\n",
    "    dataframe['OneHotMathematik'] = dataframe.JobTitle.str.lower().str.contains('mathematik').astype(int)\n",
    "    dataframe['OneHotData'] = dataframe.JobTitle.str.lower().str.contains('data').astype(int)\n",
    "    dataframe['OneHotSenior'] = dataframe.JobTitle.str.lower().str.contains('senior').astype(int)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = data_mining_job_title(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_mining_job_description(dataframe):\n",
    "    dataframe['JobDescriptionLength'] = dataframe.JobDescription.map(lambda x: len(x))\n",
    "    dataframe['CountDashboard'] = dataframe.JobDescription.str.lower().str.contains('dashboard').astype(int)\n",
    "    dataframe['CountKomplex'] = dataframe.JobDescription.str.lower().str.contains('komplex').astype(int)\n",
    "    dataframe['CountPython'] = dataframe.JobDescription.str.lower().str.contains('python').astype(int)\n",
    "    dataframe['CountJavascript'] = dataframe.JobDescription.str.lower().str.contains('javascript').astype(int)\n",
    "    dataframe['CountAnalytic'] = dataframe.JobDescription.str.lower().str.contains('analytic').astype(int)\n",
    "    dataframe['CountModel'] = dataframe.JobDescription.str.lower().str.contains('model').astype(int)\n",
    "    dataframe['CountMathematik'] = dataframe.JobDescription.str.lower().str.contains('mathematik').astype(int)\n",
    "    dataframe['CountData'] = dataframe.JobDescription.str.lower().str.contains('data').astype(int)\n",
    "    dataframe['CountHomeoffice'] = dataframe.JobDescription.str.lower().str.contains('homeoffice').astype(int)\n",
    "    dataframe['CountFlexibel'] = dataframe.JobDescription.str.lower().str.contains('flexibel').astype(int)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = data_mining_job_description(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df_new, ignore_index = True)\n",
    "df = df.sort_values('NumberOfOccurences', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Dates of Old Job Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebi\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:2023: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  return self._engine.is_unique\n",
      "C:\\Users\\Sebi\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py:928: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  return htable.duplicated(values, keep=keep)\n",
      "C:\\Users\\Sebi\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3512: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior.  In a future version these will be considered non-comparable.Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  indexer = self._engine.get_indexer(target._get_engine_target())\n"
     ]
    }
   ],
   "source": [
    "df_known_job_ids = df_links_extended[df_links_extended.ID.isin(known_job_ids)].copy()\n",
    "for index, row in df_known_job_ids.iterrows():\n",
    "    job_id = int(row.ID)\n",
    "    df.loc[df.ID == job_id, 'LatestDate'] = today\n",
    "\n",
    "df.FirstDate = pd.to_datetime(df.FirstDate)\n",
    "df.LatestDate = pd.to_datetime(df.LatestDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_ranking(row):\n",
    "    return row.OneHotDataAnalyst + row.OneHotDataScientist + row.OneHotPython + row.OneHotDeveloper + row.OneHotEngineer + \\\n",
    "    row.OneHotMathematik + row.OneHotData + row.CountDashboard + row.CountKomplex + row.CountPython + row.CountAnalytic + \\\n",
    "    row.CountModel + row.CountMathematik + row.CountData + row.CountHomeoffice + row.CountFlexibel - 2 * row.OneHotSenior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DataRanking'] = df.apply(lambda row: create_data_ranking(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_developer_ranking(row):\n",
    "    return row.OneHotPython + row.OneHotDeveloper + row.OneHotEngineer + \\\n",
    "    row.CountKomplex + row.CountPython + row.CountAnalytic + row.CountJavascript + \\\n",
    "    row.CountModel + row.CountData + row.CountHomeoffice + row.CountFlexibel - 2 * row.OneHotSenior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DeveloperRanking'] = df.apply(lambda row: create_developer_ranking(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_python_ranking(row):\n",
    "    if row.CountPython == 1:\n",
    "        count_python = row.JobDescription.lower().count('python')\n",
    "        return row.OneHotPython + row.OneHotDeveloper + row.CountHomeoffice + row.CountFlexibel + count_python\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PythonRanking'] = df.apply(lambda row: create_python_ranking(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('DataRanking', ascending = False)\n",
    "\n",
    "df = df.drop_duplicates('ID')\n",
    "df = df[df.LatestDate == pd.to_datetime(today)].copy()\n",
    "df = df[df.JobTitle != 'Cannot access url']\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clickable(val):\n",
    "    return '<a target=\"_blank\" href=\"{}\">{}</a>'.format(val, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top30(df_new, ranking):\n",
    "\n",
    "    df_new = df_new.sort_values(ranking, ascending = False)\n",
    "\n",
    "    df_links = df_new.filter(['ArticleURL', 'JobTitle', ranking, 'CompanyName', 'CompanyLocation', 'SearchTerm', 'LatestDate', 'Page', 'FirstDate'])\n",
    "    \n",
    "    df_job_watching = df_links.head(n=30).style.format({'ArticleURL': make_clickable})\n",
    "    \n",
    "    return df_job_watching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top10_new(df_new, ranking):\n",
    "\n",
    "    df_new = df_new.sort_values(ranking, ascending = False)\n",
    "    \n",
    "    newest_date = df.FirstDate.sort_values().iloc[-1]\n",
    "    \n",
    "    df_new = df_new[df_new.FirstDate == newest_date]\n",
    "\n",
    "    df_links = df_new.filter(['ArticleURL', 'JobTitle', ranking, 'CompanyName', 'CompanyLocation', 'SearchTerm', 'LatestDate', 'Page', 'FirstDate'])\n",
    "    \n",
    "    df_job_watching = df_links.head(n=10).style.format({'ArticleURL': make_clickable})\n",
    "    \n",
    "    return df_job_watching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 neue Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top10_new(df, 'PythonRanking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top10_new(df, 'DataRanking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top10_new(df, 'DeveloperRanking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top30(df, 'PythonRanking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top30(df, 'DataRanking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top30(df, 'DeveloperRanking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('JobsDataframe.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
